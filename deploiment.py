import streamlit as st 
from streamlit_option_menu import option_menu
import os
import time
import torch
from models.common import DetectMultiBackend
from PIL import Image
import numpy as np
import tempfile
import imageio
from utils.dataloaders import IMG_FORMATS, VID_FORMATS, LoadImages, LoadScreenshots, LoadStreams
from utils.torch_utils import select_device, smart_inference_mode
from utils.general import (LOGGER, Profile, check_file, check_img_size, check_imshow, check_requirements, colorstr, cv2,
                           increment_path, non_max_suppression, print_args, scale_boxes, strip_optimizer, xyxy2xywh)
import requests
from streamlit_lottie import st_lottie


def load_lottieurl(url):
    r = requests.get(url)
    if r.status_code != 200:
        return None
    return r.json()

def detectImage(image, imgsz, stride, pt, model, conf_index, iou_index, option):
    imageName = image.name
    image = Image.open(image)
    image=image.convert('RGB')
    path = f"./data/images/{imageName}"
    image.save(path)
    dataset = LoadImages(path, img_size=imgsz, stride=stride, auto=pt, vid_stride=1)
    
    bs = 1 
    model.warmup(imgsz=(1, 3, *imgsz))  
    for path, im, im0s, vid_cap, s in dataset:
        im = torch.from_numpy(im).to(model.device)
        im = im.half() if model.fp16 else im.float()  # uint8 to fp16/32
        im /= 255  # 0 - 255 to 0.0 - 1.0
        if len(im.shape) == 3:
            im = im[None]
        pred = model(im)
        # conf_thres, iou_thres = 0.25,0.25
        pred = non_max_suppression(pred,conf_index, iou_index)
    p, im0, frame = path, im0s.copy(), getattr(dataset, 'frame', 0)
    for i, det in enumerate(pred):
        if len(det):
            det[:, :4] = scale_boxes(im.shape[2:], det[:, :4], im0.shape).round()

    img= Image.open(path)

    img = np.array(img)
    a, b = st.columns(2)
    with b:
        i = 0
        for inf in det : 
            c1, c2 = (int( inf[0]), int( inf[1])), (int(inf[2]), int(inf[3]))
            # st.write(inf)
            font = cv2.FONT_HERSHEY_SIMPLEX
            font_scale = 1
            font_color = (255, 0, 0) 
            thickness = 2
            label= "TS {:.2%}".format(inf[-2])
            cv2.putText(img,label , (int( inf[0]), int( inf[1])-10), font, font_scale, font_color, thickness, cv2.LINE_AA)
            cv2.rectangle(img, c1, c2, [255,0,0], thickness=2, lineType=cv2.LINE_AA)
            st.write("Traffic Signs")
            st.write("Precision: {:.2%}".format(inf[-2]))
            imagecrop = image.crop((int(inf[0]), int(inf[1]), int(inf[2]), int(inf[3])))
            st.image(imagecrop, width=300)
            # st.divider()
            if option == "Oui":
                folder = "./media/ts"
                os.makedirs(folder, exist_ok=True)
                imagecrop.save(f"./media/ts/TS-{imageName}-{i}.jpg")
                i += 1

    # img.save("output.jpeg") 
    # os.remove(path)
    with a:
        st.image(img)
    
 
def detectVideo(video, imgsz, stride, pt, model, result, conf_index, iou_index, option):
    videoName = video.name
    tfile = tempfile.NamedTemporaryFile(delete=False)
    tfile.write(video.read())
    cap = cv2.VideoCapture(tfile.name)
    
    writer = imageio.get_writer(f'./data/videos/{videoName}', fps=cap.get(cv2.CAP_PROP_FPS), codec='libx264')
    
    max_imgsz = 2000  # Maximum allowed imgsz value (adjust if needed)
    if imgsz[0] > max_imgsz or imgsz[1] > max_imgsz:
        ratio = max(imgsz[0] / max_imgsz, imgsz[1] / max_imgsz)
        imgsz = (int(imgsz[0] / ratio), int(imgsz[1] / ratio))
    inc = 0   
    while cap.isOpened():
        ret, frame = cap.read()
        if ret:
            
            frame = cv2.resize(frame, (imgsz[0], imgsz[1]))
            
            cv2.imwrite("input3.jpg",frame)
            path = "input3.jpg"
            dataset = LoadImages(path, img_size=imgsz, stride=stride, auto=pt, vid_stride=1)
            bs = 1 
            model.warmup(imgsz=(1, 3, *imgsz))  
            for path, im, im0s, vid_cap, s in dataset:
                im = torch.from_numpy(im).to(model.device)
                im = im.half() if model.fp16 else im.float()  # uint8 to fp16/32
                im /= 255  # 0 - 255 to 0.0 - 1.0
                if len(im.shape) == 3:
                    im = im[None]
                pred = model(im)
                # conf_thres, iou_thres = conf_index, iou_index
                pred = non_max_suppression(pred,conf_index, iou_index)
            p, im0, frame = path, im0s.copy(), getattr(dataset, 'frame', 0)
            for i, det in enumerate(pred):
                if len(det):
                    det[:, :4] = scale_boxes(im.shape[2:], det[:, :4], im0.shape).round()

            img= Image.open(path)
            img = np.array(img)
            for inf in det : 
                c1, c2 = (int( inf[0]), int( inf[1])), (int(inf[2]), int(inf[3]))
                font = cv2.FONT_HERSHEY_SIMPLEX
                font_scale = 1
                font_color = (255, 0, 0) 
                thickness = 2
                label= "TS {:.2%}".format(inf[-2]) 
                cv2.putText(img,label , (int( inf[0]), int( inf[1])-10), font, font_scale, font_color, thickness, cv2.LINE_AA)
                cv2.rectangle(img, c1, c2, [255,0,0], thickness=2, lineType=cv2.LINE_AA)
                
            # writer.append_data(img)
            # i += 1
            img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
            result.image(img, width=500)
            if option == "Oui" and len(det) > 0:
                folder = "./media/frames"
                folderVideo = f"{folder}/{videoName}"
                os.makedirs(folder, exist_ok=True)
                os.makedirs(folderVideo, exist_ok=True)
                image_path = os.path.join(folderVideo, f"image_{inc}.jpg")
                img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
                cv2.imwrite(image_path, img_rgb)
                inc += 1
                # img_result = Image.open(img)
                # img_result.save(f"./media/frames/TS-{videoName}-{i}.jpg")
            # TSimage = st.empty()
            # TSimage.image(img)
            # time.sleep(1)
        else:
            break
    writer.close()

def main():
    
    st.set_page_config(page_title = "Traffic Signs", page_icon="üõë", layout="wide")

    st.markdown(
        """
        <style>
        [data-testid="stSidebar"][aria-expanded="true"] > div:first-child {
            width: 340px;
        }
        [data-testid="stSidebar"][aria-expanded="false"] > div:first-child {
            width: 340px;
            margin-left: -340px;
        }
        </style>
        """,
        unsafe_allow_html=True,
    )

    #################### Title #####################################################

    st.markdown("<h2 style='text-align: center; color: red; font-weight: bold; font-family: font of choice,    fallback font no1, sans-serif;'>D√©tection des panneaux de signalisation</h2>", unsafe_allow_html=True)
    a, b, c = st.columns((1,2,1))
    try:
        traffic_lottie = load_lottieurl('https://assets8.lottiefiles.com/packages/lf20_SDVHP8.json')
    except:
        traffic_lottie = ""
        
    with a:
        st_lottie(traffic_lottie, height=0, key="Traffic Signs")
    with b:
        st.markdown("<h4 style='text-align: center; color: grey; font-family: font of choice, fallback font no1, sans-serif;'>Projet de fin d'√©tude 2022/2023</h4>", unsafe_allow_html=True)
    with c:
        st_lottie(traffic_lottie, height=0, key="Traffic signs")

        
    device = select_device("cpu")
    with st.spinner("Veuillez patienter quelques instants..."):
        model = DetectMultiBackend("./runs/train/yolov5s_results3/weights/best.pt")
    stride, names, pt = model.stride, model.names, model.pt
    imgsz=(640, 640)
    imgsz = check_img_size(imgsz, s=stride)  # check image size
    
    
    with st.expander("A PROPOS DE NOUS", expanded=False):
        st.info("Nous sommes Aymane Fadili et Oualid Ait Aissa, √©tudiants en troisi√®me ann√©e de licence √† l'universit√© Samlalia, dans la fili√®re Science Math√©matique et Informatique (SMI) pour l'ann√©e universitaire 2022/2023. Encadr√©s par Jihad Zahir et co-encadr√©s par Ouassine Younes, nous avons r√©alis√© un stage de deux mois, du 08/05/2023 au 08/07/2023, dans le but de valider notre licence et de d√©velopper notre expertise en vision par ordinateur. Ce projet rev√™t √©galement une importance particuli√®re pour nous, car il nous permet de nous pr√©parer en vue de notre future poursuite d'√©tudes en mast√®re, avec une orientation vers la science des donn√©es. En nous impliquant activement dans la d√©tection des panneaux de signalisation routi√®re en utilisant YOLOv5 et en le d√©ployant sur la plateforme Streamlit, nous avons pu acqu√©rir des comp√©tences essentielles dans le domaine de l'analyse visuelle des donn√©es, renfor√ßant ainsi notre parcours acad√©mique et notre pr√©paration pour le mast√®re.")
        if st.button("Contact"):
            st.warning("FADILI AYMANE")
            st.write("Email: aymanefdl1@gmail.com")
            st.write("LinkedIn: https://www.linkedin.com/in/fadili-aymane")
            
            st.warning("AIT AISSA OUALID")
            st.write("Email: oualid.aitaissa@gmail.com")
            st.write("LinkedIn: https://www.linkedin.com/in/oualid-ait-aissa-914643239")
        
    with st.expander("Description de l'outil", expanded=False):
        st.info("DESCRIPTION: Le projet vise √† d√©velopper un syst√®me de d√©tection des panneaux de signalisation au Maroc en utilisant le mod√®le pr√©-entra√Æn√© YOLOv5. L'objectif principal est d'obtenir une pr√©cision √©lev√©e dans la d√©tection et la reconnaissance des panneaux de signalisation sur les routes. Ce syst√®me permettra d'am√©liorer la s√©curit√© routi√®re en identifiant de mani√®re pr√©cise et fiable les panneaux de signalisation.")
        st.info("BASE DE DONNEES: Le mod√®le est entra√Æn√© en utilisant un vaste ensemble d'images annot√©es repr√©sentant diff√©rents types de panneaux de signalisation routi√®re, accompagn√©es d'informations de localisation correspondantes. En analysant ces images √©tiquet√©es, le mod√®le acquiert la capacit√© de reconna√Ætre les caract√©ristiques visuelles sp√©cifiques des panneaux de signalisation et d'appliquer ces connaissances pour d√©tecter de nouveaux panneaux dans des images in√©dites. Ce processus d'entra√Ænement permet au mod√®le de devenir comp√©tent dans la reconnaissance pr√©cise des diff√©rents types de panneaux de signalisation, ce qui contribue grandement √† l'efficacit√© globale du projet.")
        st.info("UTILISATION: Notre projet utilise ce mod√®le pour d√©tecter les panneaux de signalisation routi√®re dans des images ou des vid√©os. Il affiche des encadr√©s autour des panneaux d√©tect√©s, fournissant ainsi une indication visuelle claire de leur emplacement.")
        # st.success("In summary, the coral detection model using YOLOv5 is a powerful artificial intelligence tool that automates the detection and identification of corals in images or videos, thus contributing to the preservation and protection of these critical marine ecosystems.")
    
    
    # with st.expander("DEPLOIMENT DU PROJET", expanded=True):
    selected = option_menu(
        menu_title=None,
        options=["D√©tection √† partir d'images", "D√©tection √† partir de Vid√©os"],
        icons=["image-fill", "camera-video-fill"],
        orientation="horizontal",
    )
    if selected == "Detection des Images":
        image = st.file_uploader("Upload image")
        if image:
            left, right = st.columns(2)
            with left:
                st.image(image,width=400)
            with right:
                conf_threshold = st.slider("Confidence Index", 0.0, 1.0, 0.25, 0.01)
                iou_threshold = st.slider("IOU Index", 0.0, 1.0, 0.45, 0.01)
                option = st.radio('Voulez-vous enregistrer les images des panneaux de signalisation¬†?', ['Oui', 'Non'])
                st.info("Le chemin d'enregistrement est:   yolov5/media/ts")
            with st.spinner("Veuillez patienter quelques instants..."):
                if st.button('Submit'):
                    # result = st.empty()
                    detectImage(image, imgsz, stride, pt, model, conf_threshold, iou_threshold, option)
        # else:
        #     st.markdown(f'<h1 style="color:#ff0000;font-size:24px;">{"First, you need to upload an image"}</h1>', unsafe_allow_html=True)
                    
    elif selected == "Detection des Videos":
        video = st.file_uploader("S√©lectionnez une vid√©o", type=['mp4', 'mov'])
        with st.spinner("Veuillez patienter quelques instants..."):
            if video:    
                left, right = st.columns(2)
                with right:
                    conf_threshold = st.slider("Confidence Index", 0.0, 1.0, 0.25, 0.01)
                    iou_threshold = st.slider("IOU Index", 0.0, 1.0, 0.45, 0.01)
                    option = st.radio('Voulez-vous enregistrer les images des panneaux de signalisation¬†?', ['Oui', 'Non'])
                    st.info("Le chemin d'enregistrement est: yolov5/media/frame")
                with left:
                    st.video(video)
                if st.button('Submit'):
                    col = st.columns(3)
                    with col[1]:
                        result = st.empty()
                        detectVideo(video, imgsz, stride, pt, model, result, conf_threshold, iou_threshold, option)                         
                        
    if st.button("Afficher les photo du panneaux de signalisation"):
        with st.expander("TRAFFIC SIGNS"):
            url = "./media/ts"
            columnNumber = 8
            col = st.columns(columnNumber)
            folder = os.listdir(url)
            for i, img in enumerate(os.listdir(url)):
                file_path = os.path.join(url, img)
                col[i%columnNumber].image(file_path, width=80)
                        

    with st.expander("RESULTATS", expanded=False): 
            
        a, b = st.columns(2)
        with a:
            st.image("./runs/train/yolov5s_results3/confusion_matrix.png",caption="Matrice de Confusion")
            st.image("./runs/train/yolov5s_results3/R_curve.png")
            st.write("Ce graphe montre la variation du rappel (Recall) en fonction de la confiance. Il permet de quantifier la capacit√© du mod√®le √† trouver tous les exemples positifs pr√©sents dans les donn√©es.")
            st.info("√Ä mesure que la confiance augmente, moins de pr√©dictions sont faites, ce qui entra√Æne une pr√©cision plus √©lev√©e mais √©ventuellement un rappel (Recall) plus faible. ")
            # st.divider()
            # st.image("./runs/train/yolov5s_results3/PR_curve.png")
        with b:
            st.image("./runs/train/yolov5s_results3/P_curve.png")
            st.write("Ce graphe montre la variation du precision en fonction de la confaiance pour √©valuer les performances du mod√®le √† diff√©rents seuils de confiance.")
            st.divider()
            st.image("./runs/train/yolov5s_results3/F1_curve.png")
            st.write("Ce graphe montre la variation du F1-score en fonction de la confiance pour √©valuer les performances d'un mod√®le de d√©tection d'objets √† diff√©rents seuils de confiance.")
            st.info("Ce graphe indique que le mod√®le de d√©tection d'objets est relativement performant dans la t√¢che √† laquelle il est confront√© [presque 80%].")
        
        
        
if __name__ == '__main__':
    main()
